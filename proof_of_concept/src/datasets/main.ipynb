{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  \\\n",
      "0  General Motors seeks to reassure Vauxhall on U...   \n",
      "1  SSE powers to 40% rise in retail profits despi...   \n",
      "2  Facebook’s cats are the new opium of the peopl...   \n",
      "3  SSE plans to triple renewable energy productio...   \n",
      "4  Tesco and Sainsbury's ban plastic cotton buds ...   \n",
      "\n",
      "                                   guardian_keywords   esg_category  \n",
      "0                                     ['job losses']         social  \n",
      "1                                    ['environment']  environmental  \n",
      "2                                         ['others']        non-esg  \n",
      "3  ['renewable energy', 'environment', 'climate c...  environmental  \n",
      "4  ['plastics', 'pollution', 'waste', 'environment']  environmental  \n",
      "shape of environmental: (10660, 3)\n",
      "shape of social: (23222, 3)\n",
      "shape of governance: (4880, 3)\n",
      "shape of non-esg: (381546, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df = pd.read_csv('./headlines_dataset/esg_headlines.csv',encoding='cp1252', low_memory=False)\n",
    "\n",
    "df.drop(['Unnamed: 0', 'mentions_company'], axis=1, inplace=True)\n",
    "\n",
    "df_env = df[(df['esg_category'] == 'environmental') & (df['guardian_keywords'].str.len() > 15)]\n",
    "df_social = df[ (df['esg_category'] == 'social') & (df['guardian_keywords'].str.len() > 8)]\n",
    "df_gov = df[ df['esg_category'] == 'governance']\n",
    "df_other = df[ df['esg_category'] == 'non-esg']\n",
    "\n",
    "dfs = [df_env, df_social, df_gov, df_other]\n",
    "for d in dfs: print(f\"shape of {d['esg_category'].iloc[0]}: {d.shape}\")\n",
    "\n",
    "# select 2000 random rows from each category\n",
    "for d in dfs:\n",
    "    d = d.sample(n=3000, random_state=1)\n",
    "    d.to_csv(f'./headlines_dataset/esg_headlines_{d[\"esg_category\"].iloc[0]}.csv',index=False, encoding='utf-8', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c1b69b0f144044b80288bd7c8c9324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching summaries:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange\n",
    "import logging\n",
    "import requests\n",
    "import traceback\n",
    "import time\n",
    "import random\n",
    "\n",
    "USER_AGENTS = [\n",
    "   #Chrome\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    #Firefox\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "]\n",
    "\n",
    "\n",
    "def get_article_url(query:str)->str:\n",
    "    \"\"\"\n",
    "     Get link to article. This is a wrapper around DDGS. text () to get the link to the article\n",
    "     \n",
    "     Args:\n",
    "     \tquery: the query to search for\n",
    "     \n",
    "     Returns: \n",
    "     \tthe link to the article or None if not found \n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Referer\": \"https://www.duckduckgo.com\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Cache-Control\": \"no-cache\",\n",
    "    \"Pragma\": \"no-cache\"\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        with DDGS(headers=headers) as ddgs:\n",
    "            results = [r for r in ddgs.text(query + \" - the guardian\", max_results=5, region='uk-en', )]\n",
    "            if results:\n",
    "                for result in results:\n",
    "                    link = result['href']\n",
    "                    if \"theguardian\" in link:\n",
    "                        return link  # Return the first valid link found\n",
    "                print(f\"No valid Guardian link found for query: {query}\")\n",
    "                return None\n",
    "            else:\n",
    "                print(f\"No results found for query: {query}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in get_article_url for query '{query}': {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        print(f\"results: {results}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_article_summary(url: str) -> str:\n",
    "    \"\"\"\n",
    "     Get the summary of an article. This is a wrapper around Article. download () and Article. parse ()\n",
    "     \n",
    "     Args:\n",
    "     \turl: URL of the article to retrieve\n",
    "     \n",
    "     Returns: \n",
    "     \tString representation of the article's summary or None if there was an error fetching the article from the url.\n",
    "    \"\"\"\n",
    "    # article = Article(url)\n",
    "    # article.download()\n",
    "    # article.parse()\n",
    "    # article.nlp()\n",
    "    # return article.summary\n",
    "    \n",
    "    if not url:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        return article.summary\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching the article summary: {type(e).__name__}, {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "df = pd.read_csv(\"./esg_only_headlines.csv\", encoding=\"utf-8\")\n",
    "\n",
    "df_res = pd.DataFrame(columns=[\"headline\", \"esg_category\", \"url\", \"summary\"])\n",
    "\n",
    "\n",
    "N = 5\n",
    "for i in trange(1000, 1000+N, desc=\"Fetching summaries\"):\n",
    "    headline = df.iloc[i][\"headline\"]\n",
    "    esg_category = df.iloc[i][\"esg_category\"]\n",
    "    \n",
    "    url = get_article_url(headline)\n",
    "    summary = get_article_summary(url)\n",
    "    \n",
    "    df_res.loc[i] = [headline, esg_category, url, summary]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>esg_category</th>\n",
       "      <th>url</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Motors seeks to reassure Vauxhall on U...</td>\n",
       "      <td>social</td>\n",
       "      <td>https://www.theguardian.com/business/2009/dec/...</td>\n",
       "      <td>Nick Reilly, the new head of GM Europe, has gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SSE powers to 40% rise in retail profits despi...</td>\n",
       "      <td>environmental</td>\n",
       "      <td>https://www.theguardian.com/business/2015/may/...</td>\n",
       "      <td>SSE has rekindled the simmering row over high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SSE plans to triple renewable energy productio...</td>\n",
       "      <td>environmental</td>\n",
       "      <td>https://www.theguardian.com/environment/2020/n...</td>\n",
       "      <td>SSE has set out plans to triple its renewable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesco and Sainsbury's ban plastic cotton buds ...</td>\n",
       "      <td>environmental</td>\n",
       "      <td>https://www.theguardian.com/environment/2016/n...</td>\n",
       "      <td>The UK’s two largest supermarket chains have c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BP leads energy companies preparing two major ...</td>\n",
       "      <td>environmental</td>\n",
       "      <td>https://www.theguardian.com/environment/2020/o...</td>\n",
       "      <td>After decades spent extracting fossil fuels fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon told: time is up for tax avoidance</td>\n",
       "      <td>governance</td>\n",
       "      <td>https://www.theguardian.com/business/2013/jul/...</td>\n",
       "      <td>Tax structures used by Amazon to route billion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>McDonald's to scrap Luxembourg tax structure</td>\n",
       "      <td>governance</td>\n",
       "      <td>https://www.theguardian.com/business/2016/dec/...</td>\n",
       "      <td>McDonald’s is to scrap its controversial Luxem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elon Musk on road to $50bn payout as Tesla's v...</td>\n",
       "      <td>governance</td>\n",
       "      <td>https://www.theguardian.com/technology/2020/ja...</td>\n",
       "      <td>The Tesla founder, Elon Musk, has taken the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why Schroders' reshuffle looks like a triumph ...</td>\n",
       "      <td>governance</td>\n",
       "      <td>https://www.theguardian.com/business/2016/mar/...</td>\n",
       "      <td>Well played, Michael Dobson, that was a terrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Royal Mail warns of job losses after sell-off</td>\n",
       "      <td>social</td>\n",
       "      <td>https://www.theguardian.com/uk-news/2013/oct/0...</td>\n",
       "      <td>Royal Mail has warned that more postal workers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline   esg_category  \\\n",
       "0  General Motors seeks to reassure Vauxhall on U...         social   \n",
       "1  SSE powers to 40% rise in retail profits despi...  environmental   \n",
       "2  SSE plans to triple renewable energy productio...  environmental   \n",
       "3  Tesco and Sainsbury's ban plastic cotton buds ...  environmental   \n",
       "4  BP leads energy companies preparing two major ...  environmental   \n",
       "5          Amazon told: time is up for tax avoidance     governance   \n",
       "6       McDonald's to scrap Luxembourg tax structure     governance   \n",
       "7  Elon Musk on road to $50bn payout as Tesla's v...     governance   \n",
       "8  Why Schroders' reshuffle looks like a triumph ...     governance   \n",
       "9      Royal Mail warns of job losses after sell-off         social   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.theguardian.com/business/2009/dec/...   \n",
       "1  https://www.theguardian.com/business/2015/may/...   \n",
       "2  https://www.theguardian.com/environment/2020/n...   \n",
       "3  https://www.theguardian.com/environment/2016/n...   \n",
       "4  https://www.theguardian.com/environment/2020/o...   \n",
       "5  https://www.theguardian.com/business/2013/jul/...   \n",
       "6  https://www.theguardian.com/business/2016/dec/...   \n",
       "7  https://www.theguardian.com/technology/2020/ja...   \n",
       "8  https://www.theguardian.com/business/2016/mar/...   \n",
       "9  https://www.theguardian.com/uk-news/2013/oct/0...   \n",
       "\n",
       "                                             summary  \n",
       "0  Nick Reilly, the new head of GM Europe, has gi...  \n",
       "1  SSE has rekindled the simmering row over high ...  \n",
       "2  SSE has set out plans to triple its renewable ...  \n",
       "3  The UK’s two largest supermarket chains have c...  \n",
       "4  After decades spent extracting fossil fuels fr...  \n",
       "5  Tax structures used by Amazon to route billion...  \n",
       "6  McDonald’s is to scrap its controversial Luxem...  \n",
       "7  The Tesla founder, Elon Musk, has taken the fi...  \n",
       "8  Well played, Michael Dobson, that was a terrif...  \n",
       "9  Royal Mail has warned that more postal workers...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load gold_standard_corpus\n",
    "dataset = pd.read_csv(\"./esg_headlines_csv.csv\", encoding='cp1252', low_memory=False)\n",
    "\n",
    "\n",
    "# remove first column and the column \"mentions_company\"\n",
    "dataset = dataset.drop(columns=['Unnamed: 0', 'mentions_company'])\n",
    "\n",
    "\n",
    "\n",
    "# count the number rows where dataset[\"esg_category\"] is not 'non-esg'\n",
    "non_esg_count = (dataset[\"esg_category\"] != 'non-esg').sum()\n",
    "print(f\"number of esg rows: {non_esg_count}\")\n",
    "\n",
    "\n",
    "# on a separate copy of esg_headlines_csv, remove all rows where esg_category is 'non-esg' and save to a new csv\n",
    "esg_dataset = dataset[dataset['esg_category'] != 'non-esg']\n",
    "esg_dataset.to_csv(\"./esg_only_headlines.csv\", index=False)\n",
    "esg_dataset.shape\n",
    "\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
